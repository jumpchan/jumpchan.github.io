<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[[Paper] Design Methodology for a Tightly Coupled VLIW/Reconfigurable Matrix Architecture: A Case Study]]></title>
    <url>%2F2019%2F06%2F21%2F2019-06-24-Paper-Case-Study-for-ADRES%2F</url>
    <content type="text"><![CDATA[Introduction该文章发表在2004年DATE会议上。主要工作是基于他们之前提出的模调度算法和对应的VLIW与CGRA紧密集成的新架构，提出的一个针对MPEG-2解码器应用的基于C的设计流案例，以此说明他们的设计方法能够完整映射一个应用到可重构系统中，并取得预期的堪比直接软件开发的性能。需要注意整个应用一般包含决定时间的规则化代码段和大量非规则的控制密集型代码，决定时间的往往是循环。考虑到应用代码的两个部分，一般硬件架构设计成由一个可重构阵列和一个处理器组成的架构（可将循环映射到阵列上加速，而控制密集型代码由处理器执行），处理器往往是一个RISC。其实这样的架构/系统设计是类似于软硬件协同设计问题的。 Research TeamTeam Informations该论文的主要研究者与2002年FPT上DRESC (Dynamically Reconfigurable Embedded System Compiler) 和2003年FPL上ADRES (Architecture for Dynamic Reconfigurable Embedded Systems) 的主要研究者是同一拨人。 Previous Related Works一套编译系统：DRESC【这是一套针对CGRA的编译系统？】Questions 一个新的架构：ADRES这是一个超长指令字（Very Long Instruction Word, VLIW）和可重构阵列（reconfigurable matrix）紧密连接的架构模板（template）。区别于松散连接的精简指令集（Reduced Instruction Set Computing, RISC）和可重构阵列架构，ADRES取得了一些优势。【哪些优势？】Questions 新的模调度算法2003年DATE的一篇文章，提出一个新的模调度算法，用于他们提出的ADRES架构。【是否集成在DRESC中？】Questions 硬件架构：ADRES Architecture OverviewADRES架构的整体系统结构如下图所示，类似于一个处理器，其执行核心（core）与【分级存储器？】Questions（memory hierarchy）相连。 系统中的ADRES核心如下图所示，包含诸多组件，例如：【功能单元？】（Function Units, FUs）and 【寄存器组？】（register files, RF）。Questions 该核心有两个功能区域，这两个区域共享一些资源，如上图阴影部分所示，但因为【处理器/协处理器？】Questions（processor/co-processor）模型，这两个区域在执行时永远不会在共享资源上有重叠。这两部分分别为： 超长指令字处理器：利用指令级并行（instruction-level parallelism, ILP）执行无计算内核（kernel）的代码。 这是一个典型的VLIW架构，分配一些FU，并用一个多端口（port）的RF将它们连接起来。而这些FU还能通过可用的端口与memory hierarchy相连。 可重构阵列：用高并行度的方式加速类数据流（dataflow-like）计算内核（kernel）。 除了与VLIW处理器共享的FU和RF部分，可重构阵列部分还有一些包含了FU和RF的可重构单元（reconfigurable cells, RC），其构造如下图所示。 FU可以是异构的，来支持不同的操作集。为了从循环（loop）中分离出控制流，FU支持预测操作（predicted operation）。 多路器（multiplexors）用于和其他资源数据直连。 配置存储器（configuration RAM）则本地（locally）存储一些【配置文本？】（configuration contexts）Questions。 配置环境可以在每个周期（cycle-by-cycle）从配置存储器中被循环读取。 当本地配置存储器不够大时，配置环境也可以从memory hierarchy中读取，但会造成额外的延迟开销。 存储的共享（share）用于支持VLIW处理器与可重构阵列之间的通信，例如RF和memory hierarchy的共享。 ADRES的VLIW和可重构阵列紧密连接架构的优势： 用VLIW能够加速非计算内核代码（non-kernel code），这些代码也往往是很多应用的瓶颈，而RISC不行； 通过RF和内存存储的共享极大的降低了通信开销和编程复杂度； 共享的资源能够极大降低【资源？】Questions开销（costs） 基于C的设计流ADRES的设计流如下图所示： 一个设计开始于使用C语言描述的应用，作为输入之一引入设计流。上图的右侧则是涉及目标硬件架构的基于XML的描述，作为另一个输入引入设计流。具体描述如下： profiling/partitioning：发现候选循环（loop），将在执行期映射到可重构阵列（P.S. 主要依靠人工识别） Source-level transformations：重构计算内核（kernel），以允许流水化 IMPACT：是一个主要针对VLIW的编译器框架，用来语法解析、分析和优化C代码 Lcode：IMPACT生成的一个中间表示，作为调度（scheduling）的输入 Architecture：XML描述的语法分析和抽象，转化架构描述为内部图表示 接受应用程序和硬件表示作为输入，该工具分两个部分进行处理 模调度（modulo scheduling）算法使得计算内核能够达到高并行度 同时传统指令级并行调度使得非内核代码达到中度并行 这两部分的通信由工具发现并提供【是由register allocation部分负责吗？】Questions 为VLIW和可重构阵列生成调度后代码，可由联合仿真器（co-simulator）进行仿真 另外一个正在进行的工作是内核调度，当配置存储器（configuration RAM）不能储存所有的内核时，该算法能够降低配置开销 一个中央配置文件（setting file）控制整个编译过程Question1，包括整个设计环境和每个单独的循环。因此允许编译器在某一时刻集中关注单个循环，这种策略能降低设计时间，如下图所示。 第一步，针对单个循环loop1，先进行源代码级转换输出loop1*，并由VLIW进行验证。这一步的用时极少； 第二步，则是对loop1*进行模调度，该文中的模调度算法类似一个布局布线算法，但仍然很耗时； 模调度尝试找到一个调度，拥有尽量小的【启动间距？】（initiation interval, II）Questions，即便II只有1的差距，也会造成很大影响； 为了找到一个更小的II，值得耗时进行多次尝试，而如果模调度始终找不到好的解决方案，就返回源码级转换进行更多改进，直到找到一个合适的调度； 接着，暂存loop1*的映射到VLIW； 返回第一步迭代处理loop2，直到所有的循环均成果映射到可重构阵列上进行加速； 最后多个循环能被中央setting file整合起来，而不会发生特殊情况造成结果不确定。 这种设计策略的有点包括，能够使焦点专注于单个循环的映射，且每个循环能够被co-simulator验证，且对并行化设计流很有帮助。而两个硬件部分VLIW和可重构阵列之间的通信，也因为紧密的硬件架构，变得能够依靠编译器自动化进行，且开销很小。仅需识别两部分需要产生和消耗的实时变量，并将其存入共享RF（VLIW RF）中即可，而通过内存空间的通信则更无须特别做什么，这两部分共享内存访问。 MPEG-2解码器映射案例MPEG-2解码器是一个多媒体领域的应用，需要很高的计算能耗。其大多执行时间消耗在若干计算内核（kernel）上，因此很适合用可重构架构来运行。该案例使用一个C实现的实例，源自MPEG Software Simulation Group (MSSG)。该实现的代码对处理器高度优化过，且是MediaBench的一部分。整个应用包含21个文件，共一万行左右代码。 映射到ADRES架构 profiling：人工识别到应用中有14处循环（loop），作为可重构阵列的流水候选。另外，为了进一步提升性能，该文作者还从VLD(variable length decoding)循环中抽取出2个去量化循环，用于在可重构阵列中加速，如下图所示。所有16处循环占总执行时间的84.6%，却仅占总代码量的3.3%。 source-level transformation：除了少部分能直接映射的循环，其余需要先进行循环转换。 例如下图中IDCT（inverse dis- crete cosine transformation）计算内核，其内层循环体，是一个函数，因此对于可重构阵列是不可流水化的。 首先把循环体函数（图中的idctrow）的操作放入循环内 接着把非规则计算（图中的shortcut）移除，使得循环更规则化 最后把idct应用到一个微块上，使其符合硬件8x8的尺寸。对于MPEG-2视频一般使用6个8x8到块，也使得原来的8次迭代增加到64次迭代，极大降低了流水开支question2。 对于其他的不易流水化的循环，还有更多的转换方法， 例如循环展开（loop unrolling）、【循环扁平化？】（loop flattening）、【变量复制？】（variable replicating）等Questions 但这些到目前（2004年）都需要根据设计者的经验来选择合适的。 该文作者使用3天来完成应用程序中这些循环的C到C改写，实现循环转换。 当所有循环都被工具成功映射后，可以为每个循环获取其配置context。 而当MPEG-2应用到输入视频，改变大小时，循环数量会相应增加，导致配置存储器可能不够，因此该文正在解决的技术是内核调度技术。 映射实验结果为了做实验，使用来一个类似MorphoSys的硬件实例作为ADRES模板的实现。 总共64个FU，被分为四片（tile），每片包含4x4的FU； 每个FU除了能连接相邻4个FU，还可以连接所有同一tile中的同行和同列FU，另外整个阵列还有行总线和列总线； 第一行FU能够被VLIW处理器使用，并连接到一个多端口寄存器组上； 只有第一行的FU能够执行内存操作，例如load/store操作。 实验结果如下图所示，第四列是Instruction-per-cycle（IPC）；第五列是total pipeline stages。第六列调度时间是在Pentium 4 1.7GHz/Linux PC平台上运行的CPU时间。 【上述图示均为文中图片，有待重画】Questions Questions. 用【】框起来的内容为尚未确定或者待解决的问题 &#8617; Question1. 【是不是存储在中央寄存器组中？因为该硬件与这个文件的属性很相符】 &#8617; question2. 流水开支是指？怎么降低流水开支的？ &#8617; Reference [1] Mei, Bingfeng, Serge Vernalde, Diederik Verkest, and Rudy Lauwereins. “Design methodology for a tightly coupled VLIW/reconfigurable matrix architecture: A case study.” In Proceedings of the conference on Design, automation and test in Europe-Volume 2, p. 21224. IEEE Computer Society, 2004. (Sites: IEEE) Back[2] Mei, Bingfeng, Serge Vernalde, Diederik Verkest, Hugo De Man, and Rudy Lauwereins. “DRESC: A retargetable compiler for coarse-grained reconfigurable architectures.” In 2002 IEEE International Conference on Field-Programmable Technology, 2002.(FPT). Proceedings., pp. 166-173. IEEE, 2002. (Sites: IEEE) Back[3] Mei, Bingfeng, Serge Vernalde, Diederik Verkest, Hugo De Man, and Rudy Lauwereins. “ADRES: An architecture with tightly coupled VLIW processor and coarse-grained reconfigurable matrix.” In International Conference on Field Programmable Logic and Applications, pp. 61-70. Springer, Berlin, Heidelberg, 2003. (Sites: Springer) Back[4] Mei, Bingfeng, Serge Vernalde, Diederik Verkest, Hugo De Man, and Rudy Lauwereins. “Exploiting Loop-Level Parallelism on Coarse-Grained Reconfigurable Architectures Using Modulo Scheduling.” In Proceedings of the conference on Design, Automation and Test in Europe-Volume 1, p. 10296. IEEE Computer Society, 2003. (Sites: IEEE) Back]]></content>
  </entry>
  <entry>
    <title><![CDATA[[Survey] CGRA]]></title>
    <url>%2F2019%2F06%2F14%2F2019-06-17-Survey-CGRA%2F</url>
    <content type="text"><![CDATA[摘要计算密集型应用的硬件加速往往通过映射技术将密集计算映射（Mapping）到可重构计算（Reconfigurable Computing, RC）芯片上。而一般而言，应用执行时间主要消耗在少量的循环处。因此，可重构计算芯片上的循环映射优化对于提升计算密集型应用的执行性能具有重要意义。CGRA（Coarse-Grained Reconfigurable Architecture）是一种可重构计算架构，字面翻译为粗粒度可重构处理器。其基础处理单元（Processing Element, PE）为指令级别（Word-Level）的，区别于FPGA（Field Programable Gate Array, 现场可编程门阵列）的门级别，能够直接实现一些典型的逻辑计算。由于CGRA上特殊的硬件结构以及循环程序中语句复杂的依赖关系，CGRA上的循环映射也存在着挑战。 可重构处理器体系结构硬件简介及基本属性组成：PE组成的Array由一个类mesh风格的内部连线连接起来的架构 属性：由于大量的资源因此有高吞吐量而分布式的硬件带来低功耗动态可编程则提供高灵活性 主要参数：大小：PE 数量，一般构成一个正方形的阵列，一般44～88，也有32*32互连形式：crossbar；mesh；mesh plus；morphosys……寄存器共享方式：完全分布式；bus行列分布式；中央寄存器式；混合式PE 功能：同构/异构；ALU功能类型；PE动态功能…… 硬件分类根据程序运行的过程中阵列的电路结构是否改变，分为： 静态可重构：如FPGA 动态可重构：如CGRA 根据阵列互连形式的不同，CGRA主要分为： 一维互连CGRA 二维互连CGRA 可重构处理器编译技术编译对可重构计算的重要性由于可重构处理器和通用处理器的硬件结构有很大的不同，可重构处理器编译器的编译流程和生成的可执行文件都有很大的不同。 通用处理器的编译是将应用程序编译生成单一目标处理器的汇编指令和机器码。 而可重构处理器编译器则首先要对应用程序进行软硬件划分，把应用程序中适合硬件加速的计算密集型部分划分出来。然后针对两部分分别作编译处理，分别生产运行在主控制器控制码和可重构计算阵列上配置信息。 因此，我们所熟知的串行编程模式不能够被直接应用在可重构处理器上。可重构处理器编译是一个极具挑战性的工作。如果没 有易用的编译器，编程人员则需要非常熟悉可重构处理器的底层硬件结构来进行 开发。这将大大降低可重构处理器的通用性。因此，可重构处理器编译器对于可 重构处理器具有极为重要的作用。 CGRA循环映射技术为何要针对循环进行映射优化？ 因为在现代实际生活应用程序中(例如:声音、图像处理等应用)，循环往往占据了这些程序的大部分运行时间。循环的特点是多次重复同一个计算内核（Kernel），不改变运算的结构，只改变运算的数据。[2] 因此循环映射技术往往是针对从某类应用程序中抽象出的计算内核来进行优化的。 CGRA映射（Mapping）技术根据PE在映射时的功能，可分为两类映射技术： 空间映射：主要针对一维互连架构 时域映射：主要针对二维互连架构 根据可重构计算阵列的运算模式，可分为下列两种情况： 一次配置多次执行：由于少量的配置，可以大大节省配置的开销，从而可以提高性能，降低功耗。 一次配置一次执行：提高来可配置性，但大大降低可重构处理器的执行性能，功耗也会大大增加。 总之，降低配置次数对于提高可重构处 理器的性能是非常有帮助的。 挑战 多层嵌套循环如何处理，以降低内外循环之间交互的开销，同时保证各个循环之间执行顺序的正确性。 由于循环间的数据依赖，如何在限定的空间资源和时序约束中进行合法的布局布线也是一个难点。 选取合适的循环变换可以改变数据依赖的形式，以更好得进行映射，因此如何选择循环变换方法就是一个挑战； 硬件资源有限，如何充分地利用有限的各类硬件资源对于循环映射也是一个挑战： 有限的配置存储资源：如果配置存储资源不够，动态可重构的能力会非常受限。因此，如何在循环映射的时候减少配置代价是一个难点； 稀疏的计算和互连资源：由于芯片面积和功耗的限制，计算阵列的规模一般不大，且阵列中计算单元之间的互连资源一般也比较稀疏； 有限的数据存储资源：主要体现在带宽和存储空间上，由于芯片面积和功耗的限制，阵列中只有某些处理单元能够访问数据存储器； 调度算法布局布线]]></content>
      <categories>
        <category>Reconfigurable Computing</category>
      </categories>
      <tags>
        <tag>Survey</tag>
        <tag>CGRA</tag>
        <tag>Mapping</tag>
        <tag>Architecture</tag>
        <tag>Scheduling</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Compiler Overview]]></title>
    <url>%2F2019%2F03%2F06%2F2019-03-06-Compiler-Overview%2F</url>
    <content type="text"><![CDATA[Program Execution 程序执行计算机程序执行过程主要涉及四个部分，包括代码、翻译、中间表示和执行。其中侠义的编译器属于翻译部分，而一个完整的编译系统的执行包含了所有四个部分。 Code 代码代码（Code）是指由计算机程序的形式编码而成的一系列指令集合，它能够由计算机执行。在计算机硬件上运行软件需要两个部分，一个是代码（Code），另一个是数据（Data）。 计算机只能直接执行由指令集中指令构成的机器码（Machine Code）。但不论是机器码还是其他低级程序语言，都不是可以简单阅读的，因此大多源码（Source Code）都是由高级程序语言编写的。而编译器（Compiler）或者解释器（Interpreter）则将源码翻译成计算机可执行的机器语言。一个编译器生成的是目标代码（Object Code），一般来说就是机器语言（Machine Language）构成的，但也包括一些比源码更低级别的中间语言（Intermediate Language）。而解释器则是解释字节码（Bytecode）的工具，字节码是一种比源码低级的代码。 接下来具体说明代码的不同种类。 Source Code任意的使用人类可读的程序语言编写的代码组合都可称为源码（Source Code），它可能包含注释，一般使用富文本表达。源码一般会被汇编器（Assembler）或者编译器（Compiler）翻译成二进制机器码（Binary Machine Code），从而能够直接被计算机理解，这段机器码可能会被存储起来，从而晚一点再执行。除此之外，源码也可能被解释，从而立即执行。 Object Code目标代码（Object Code）是编译器的产物。通常来讲，目标码是一段状态或者指令的序列，它是由一种计算机语言表示的，一般是一种机器码语言或者中间语言，例如RTL (Register Transfer Language)就是一种中间语言。 BytecodeMachine CodeMicrocodeTranslator (Computing)CompilerCompile-timeOptimizing CompilerIntermediate Representation (IR)ExecutionRuntime SystemRuntimeExecutableInterpreterVirtual Machine Compilation StrategiesJust-in-Time (JIT)Tracing Just-in-TimeAhead-of-Time (AOT)TranscompilationRecompilation]]></content>
      <categories>
        <category>Compiler</category>
      </categories>
      <tags>
        <tag>Compiler</tag>
        <tag>Overview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CGO Compiler]]></title>
    <url>%2F2019%2F02%2F27%2F2019-02-27-CGO-Compiler%2F</url>
    <content type="text"><![CDATA[International Symposium on Code Generation and Optimization (CGO) 是和International Symposium on High-Performance Computer Architecture (HPCA)，ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPoPP)，International Conference on Compiler Construction (CC)合作的。 This is a record of reading about working shop on CGO 19’. The workshop included talks from various projects - Julia (Julia Computing), TVM (UW), Glow (Facebook), XLA (Google), nGraph (Intel), TensorRT (Nvidia), xDNN (Xilinx, DeePhi DP(https://www.xilinx.com/products/design-tools/developer-forum.html)U) and the soon to release MLIR (Google). Workshop on Compilers for Machine Learning (C4ML)Julia: A Compiler to compile Code from Julia to XLA “Getting to Machine Learning from a General Purpose Compiler”, Keno Fischer, Jameson Nash, Julia Computing.Presentation: PDF, Blog 这个编译器的目标是编译Julia代码到TPU平台的XLA代码上，因此编译器的Backend是LLVM。而LLVM是一个静态编译Backend，而Julia语言在语义上是动态语言，因此编译器需要转化原语言中的动态语义到LLVM的静态语义表示。]]></content>
      <categories>
        <category>Conference</category>
      </categories>
      <tags>
        <tag>Record</tag>
        <tag>Compiler</tag>
        <tag>Computer Architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Domain Specific Words]]></title>
    <url>%2F2019%2F02%2F25%2F2019-02-25-Domain-Specific-Words%2F</url>
    <content type="text"><![CDATA[This is a record of normal words in computer science domain. Domain Specific WordsVanilla CodeVanilla often refers to pure or plain. So in terms of programming languages, it means either without the use of 3rd party libraries or without the use of frameworks. 在计算机编程的范畴中，通常表示不使用第三方库或任何相关的框架平台等。]]></content>
      <categories>
        <category>General Concept</category>
      </categories>
      <tags>
        <tag>Computer Science</tag>
        <tag>Record</tag>
      </tags>
  </entry>
</search>
