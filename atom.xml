<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>QP.Chen Talk</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://qpchen.tk/"/>
  <updated>2019-07-18T15:07:26.000Z</updated>
  <id>http://qpchen.tk/</id>
  
  <author>
    <name>QP.Chen</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>[Paper] DNestMap: Mapping Deeply-Nested Loops on Ultra-Low Power CGRAs</title>
    <link href="http://qpchen.tk/2019/07/18/2019-07-18-Paper-DNestMap/"/>
    <id>http://qpchen.tk/2019/07/18/2019-07-18-Paper-DNestMap/</id>
    <published>2019-07-18T21:56:43.000Z</published>
    <updated>2019-07-18T15:07:26.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>该文针对极低功耗CGRA中配置内存受限（很小）的情况，提出一个映射方法，映射包含深度嵌套循环和非规则控制流结构的应用。<br>该方法将应用和CGRA进行划分（partitioning），从多个嵌套循环中提取出最合适的代码块做映射，从而有效地通过时空（spatio-temporal）划分静态缓存这些划分后的代码块配置信息到配置内存中，以较少的启动间隔（II）代价，获得较多的配置内存加载时间降低，从而加快整体执行时间。</p><a id="more"></a><h2 id="团队"><a href="#团队" class="headerlink" title="团队"></a>团队</h2><p>新加坡国立大学的工作，从2017年DAC上的HyCUBE硬件架构，到2018年DAC上该论文关于映射深度嵌套循环到极低功耗CGRA上的工作。</p><h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><ul><li>关于解决CMEM限制问题，有将配置内存当作缓存（cache），从时间上动态缓存配置信息的几种工作。<ul><li>包括cache prefetching、配置信息管理策略优化和多面体配置等工作；</li></ul></li><li>关于该文方法的各个步骤的解决方法，涉及如下几种技术：<ul><li>三维正交背包问题（3D orthogonal knapsack, 3D-OKP）</li><li>操作（Operation）的Packing Class抽象</li><li>三维正交Packing问题(Orthogonal Packing Problem of 3-Dimension, OPP-3D)</li><li>分支界限搜索（branch-and-bound search, B&amp;B search）</li></ul></li></ul><h2 id="贡献和动机"><a href="#贡献和动机" class="headerlink" title="贡献和动机"></a>贡献和动机</h2><p>大多数应用包含嵌套循环，而当前大部分映射方法仅针对最内层循环，未考虑应用程序中复杂嵌套循环以及非规则控制流的部分如何映射。当映射该部分源码时，会对配置内存（Configuration Memory, CMEM）产生容量要求。针对超低功耗CGRA中CMEM极小时，嵌套循环用传统映射方法则会从片外内存频繁读取配置信息，在片上CMEM产生交换（swap）代价。</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>【相关工作中的各个步骤的解决技术，需要进一步了解，以深入该文到底如何设计时空配置信息缓存方法的】<br><!-- writing here --></p><!-- ![Alt_text](site "Title") --><!-- <img class="site 500 Title"> --><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="待商讨问题"><a href="#待商讨问题" class="headerlink" title="待商讨问题"></a>待商讨问题</h3><ul><li>针对MU到PE块的映射，用ILP求得局部最优解（此时尺寸都很小，求解应该很快），再做PEA划分等问题，能否提高质量？</li><li>既然整个运行时间包含很多breakdown的部分，能否用一种综合打分的机制，统一评价映射方法以及架构设计的好坏？</li></ul><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><blockquote><p>[1] $Reference (Sites: <a href="$site" title="[1] $[Paper] DNestMap: Mapping Deeply-Nested Loops on Ultra-Low Power CGRAs">$Publisher</a>) <a href="#简介">Back</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;该文针对极低功耗CGRA中配置内存受限（很小）的情况，提出一个映射方法，映射包含深度嵌套循环和非规则控制流结构的应用。&lt;br&gt;该方法将应用和CGRA进行划分（partitioning），从多个嵌套循环中提取出最合适的代码块做映射，从而有效地通过时空（spatio-temporal）划分静态缓存这些划分后的代码块配置信息到配置内存中，以较少的启动间隔（II）代价，获得较多的配置内存加载时间降低，从而加快整体执行时间。&lt;/p&gt;
    
    </summary>
    
      <category term="Reconfigurable Computing" scheme="http://qpchen.tk/categories/Reconfigurable-Computing/"/>
    
    
      <category term="CGRA" scheme="http://qpchen.tk/tags/CGRA/"/>
    
      <category term="Configuration Memory" scheme="http://qpchen.tk/tags/Configuration-Memory/"/>
    
      <category term="Nested Loop" scheme="http://qpchen.tk/tags/Nested-Loop/"/>
    
      <category term="Cache" scheme="http://qpchen.tk/tags/Cache/"/>
    
      <category term="Partitioning" scheme="http://qpchen.tk/tags/Partitioning/"/>
    
      <category term="Packing" scheme="http://qpchen.tk/tags/Packing/"/>
    
      <category term="HyCUBE" scheme="http://qpchen.tk/tags/HyCUBE/"/>
    
  </entry>
  
  <entry>
    <title>[Paper] Architecture Exploration of Standard-Cell and FPGA-Overlay CGRAs Using the Open-Source CGRA-ME Framework</title>
    <link href="http://qpchen.tk/2019/07/17/2019-07-17-Paper-Physical-Implementation-of-CGRA-ME/"/>
    <id>http://qpchen.tk/2019/07/17/2019-07-17-Paper-Physical-Implementation-of-CGRA-ME/</id>
    <published>2019-07-17T22:40:03.000Z</published>
    <updated>2019-07-18T15:07:26.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Jason Anderson组CGRA-ME发布的首篇论文中，介绍其物理实现功能时，在ASIC上实现了Standard Cell CGRA。而该文则是继CGRA-ME发布后，扩充其物理实现功能，在FPGA上实现FPGA Overlay CGRA，并探索CGRA-ME如何在同一平台上比较CGRA的不同物理实现的性能、质量、能耗等指标。</p><a id="more"></a><h2 id="团队"><a href="#团队" class="headerlink" title="团队"></a>团队</h2><p>多伦多大学ECE部门的Jason H. Anderson组。</p><h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>针对CGRA-ME的三大功能：架构建模、应用映射和物理实现，分别有如下三种相关工作：</p><ul><li>CGADL建模语言，能描述CGRA架构，但没有实现应用的映射以及RTL输出；</li><li>DRESC、SPR等映射系统，但没有集成到架构建模框架中；</li><li>各个硬件架构的物理实现工具也有很多工作，但都没有整合到一个大的统一框架中，以至于很难直接互相比较。</li></ul><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><h4 id="Overlay"><a href="#Overlay" class="headerlink" title="Overlay"></a>Overlay</h4><p>Overlay本身是网络的虚拟化技术，用在FPGA上则是虚拟平台，简而言之其框架如下三个部分：</p><ul><li>应用：用HDL、C等实现的应用程序<ul><li>通过overlay mapping映射到虚拟平台</li></ul></li><li>Overlay：用CGRA等设计的虚拟平台<ul><li>通过物理映射和配置等映射到底层硬件上</li></ul></li><li>FPGA：包括LUT、RAM等组件</li></ul><h2 id="贡献和动机"><a href="#贡献和动机" class="headerlink" title="贡献和动机"></a>贡献和动机</h2><p>似乎框架类论文的发表，都有系列论文产生的规律，从DRESC到CGRA-ME。这一系列包括首发论文介绍框架，案例论文介绍使用，有时还有众多其中创新组件的单独论文。<br>而该文就是CGRA-ME关于三大功能之一的物理实现的案例论文。</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>该案例中CGRA-ME的架构如下图所示。需要注意的是数据流图是从源码中基于人工标注提取出来的。</p><p><img src="https://qpimg.ml/images/2019/07/17/CGRA-ME-framework-overview-showing-the-main-components.png" alt="CGRA-ME_framework_overview" title="CGRA-ME framework overview showing the main components"></p><p>上图中CGRA-ME到三个主要功能包括：</p><ul><li>从2的CGRA-ADL描述的架构到4输出的MRRG架构模型；</li><li>从1的包含人工标注数据流图DFG的应用源码到6的映射工具输出映射结果和配置流；</li><li>从2的CGRA-ADL描述的架构到7的RTL硬件描述语言生成，从而到模拟器或者硬件实现。</li></ul><p>其中CGRA-ADL理论上能够描述任意CGRA架构；</p><p>映射模型则是能扩展到任意CGRA架构的整数线性规划（ILP）映射模型，能理论上产生最优解。虽然理论上映射速度最慢，但该文中针对所有Benchmark映射到$4\times4$尺寸CGRA的时间不超过12分钟。<sup><a href="#fn_Question:大规模" id="reffn_Question:大规模">Question:大规模</a></sup></p><p>最后CGRA的物理实现一般有三种方式：定制芯片；一个standard-cell ASIC；在FPGA上作为一层Overlay。其中定制CGRA芯片的成本太高，因此该文实现并比较了后两种方式实现的CGRA。</p><!-- ![Alt_text](site "Title") --><!-- <img class="site 500 Title"> --><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>该文主要定义了基于ADRES架构模板的两个$4\times4$的变种架构实例，如下图所示，并对这两个CGRA实例在ASIC和FPGA物理硬件上进行了实现和比较。</p><img src="https://qpimg.ml/images/2019/07/18/22Full22-and-22Reduced22-variants-of-ADRES-architec--ture.png" width="500" title="Full and Reduced variants of ADRES architec- ture"><h3 id="Standard-Cell-CGRA"><a href="#Standard-Cell-CGRA" class="headerlink" title="Standard-Cell CGRA"></a>Standard-Cell CGRA</h3><p>其中ASIC用的FreePDK45 standard-cell library，一个实验用途的开源45nm standard-cell库。而CGRA-ME生成的Verilog则用Synopsys‘ Design Compiler进行技术映射，具体分为最小面积（area）和最小时延（delay）两种映射；然后分析area breakdown，如下图所示；</p><img src="https://qpimg.ml/images/2019/07/18/Standard-cell-area-breakdown-of-Full-and-Reduced-architectures-when-targeting-minimum-area-and-minimum-delay.png" width="600" title="Standard-cell area breakdown of Full and Reduced architectures, when targeting minimum area and minimum delay"><p>接着将映射设计netlist输入standard-cell P&amp;R工具Cadence’s Innovus，得到的P&amp;R平面图如下图所示，输出SPEF文件和整个芯片面积（area），如下表第一列；最后用Synopsys’ PrimeTime工具在设计netlist和SPEF文件基础上，进行静态时间分析（Static Timing Analysis, STA），得到芯片工作频率参数，如下表第二列。</p><img src="https://qpimg.ml/images/2019/07/18/Floorplan-for-Cadences-Innovus-place-and-route.png" width="400" title="Floorplan for Cadence’s Innovus place and route"><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">Full Arch Min Area</th><th style="text-align:center">Full Arch Min Delay</th><th style="text-align:center">Reduced Arch Min Area</th><th style="text-align:center">Reduced Arch Min Delay</th></tr></thead><tbody><tr><td style="text-align:center">Area [μm2]</td><td style="text-align:center">317927.0</td><td style="text-align:center">403753.2</td><td style="text-align:center">253239.8</td><td style="text-align:center">327189.2</td></tr><tr><td style="text-align:center">FMax [MHz]</td><td style="text-align:center">140</td><td style="text-align:center">164</td><td style="text-align:center">142</td><td style="text-align:center">192</td></tr></tbody></table></div><p>而最后四种设计的硬件排布（layout）的物理视角和变形视角如下图所示。</p><img src="https://qpimg.ml/images/2019/07/18/Standard-cell-layout-for-all-four-designs-in-physical-view.png" width="300" title="Standard-cell layout for all four designs in physical view"><img src="https://qpimg.ml/images/2019/07/18/Standard-cell-layout-for-all-four-designs-in-amoeba-view.png" width="300" title="Standard-cell layout for all four designs in amoeba view"><h3 id="FPGA-Overlay-CGRA"><a href="#FPGA-Overlay-CGRA" class="headerlink" title="FPGA-Overlay CGRA"></a>FPGA-Overlay CGRA</h3><p>而FPGA的实验则用45nm的Altera Stratix IV FPGA芯片，在Altera/Intel的Quartus Prime 16.1上实现。而因为该FPGA上要实现CGRA的乘法器功能，只有通过DSP块。而由于该芯片DSP分布在某些列上，鉴于CGRA的设计需求，在硬件实现时DSP之间的LUT-based块将不会被充分利用。</p><p>在Stratix IV上实现两种架构，分析area breakdown得到下图，而统计的总体面积和性能参数如下表所示。其中面积的单位是ALMs（adaptive logic modules），每个ALM包含一个2输出可分割6输入LUT、一个进位链电路（carry-chain circuitry）和2个触发器（flip-flop）。另外包含乘法器（multiplier）的逻辑块使用Stratix IV中的DSP块，该面积并未列在表中统计。</p><img src="https://qpimg.ml/images/2019/07/18/FPGA-area-breakdown-for-both-architecture-vari--ants.png" width="500" title="FPGA area breakdown for both architecture vari- ants"><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">Full Arch</th><th style="text-align:center">Reduced Arch</th></tr></thead><tbody><tr><td style="text-align:center">Area [ALM]</td><td style="text-align:center">8803</td><td style="text-align:center">7192</td></tr><tr><td style="text-align:center">FMax [MHz]</td><td style="text-align:center">89</td><td style="text-align:center">103</td></tr></tbody></table></div><p>最后得到的FPGA实现硬件平面设计图如下图所示。</p><img src="https://qpimg.ml/images/2019/07/18/Floorplanned-Stratix-IV-implementations-of-ho--mogeneous-CGRA-with-torus-connections-left-and-hetero--geneous-CGRA-without-torus-connections-right.png" width="500" title="Floorplanned Stratix IV implementations of ho- mogeneous CGRA with torus connections (left), and hetero- geneous CGRA without torus connections (right)"><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>CGRA-ME集合了三大功能于一身，包括架构建模、应用映射和物理实现，提供了一个统一的CGRA设计平台。<sup><a href="#fn_Question:定制芯片" id="reffn_Question:定制芯片">Question:定制芯片</a></sup></p><blockquote id="fn_Question:大规模"><sup>Question:大规模</sup>. 但未知大规模情况下如何，就如FPGA的VPR和Titan Benchmark运行时间上的差别，但相应但CGRA也需要有大规模的架构设计。<a href="#reffn_Question:大规模" title="Jump back to footnote [Question:大规模] in the text."> &#8617;</a></blockquote><blockquote id="fn_Question:定制芯片"><sup>Question:定制芯片</sup>. 该文物理实现案例中并未提供第一种实现方式，也就是在定制芯片上实现，不知此方法能否用GEM5实现？CCF是否使用的这种实现方式？<a href="#reffn_Question:定制芯片" title="Jump back to footnote [Question:定制芯片] in the text."> &#8617;</a></blockquote><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><blockquote><p>[1] $Reference (Sites: <a href="$site" title="[1] $[Paper] Architecture Exploration of Standard-Cell and FPGA-Overlay CGRAs Using the Open-Source CGRA-ME Framework">$Publisher</a>) <a href="#简介">Back</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;Jason Anderson组CGRA-ME发布的首篇论文中，介绍其物理实现功能时，在ASIC上实现了Standard Cell CGRA。而该文则是继CGRA-ME发布后，扩充其物理实现功能，在FPGA上实现FPGA Overlay CGRA，并探索CGRA-ME如何在同一平台上比较CGRA的不同物理实现的性能、质量、能耗等指标。&lt;/p&gt;
    
    </summary>
    
      <category term="Reconfigurable Computing" scheme="http://qpchen.tk/categories/Reconfigurable-Computing/"/>
    
    
      <category term="CGRA" scheme="http://qpchen.tk/tags/CGRA/"/>
    
      <category term="CGRA-ME" scheme="http://qpchen.tk/tags/CGRA-ME/"/>
    
      <category term="FPGA Overlay" scheme="http://qpchen.tk/tags/FPGA-Overlay/"/>
    
      <category term="Standard Cell" scheme="http://qpchen.tk/tags/Standard-Cell/"/>
    
      <category term="Physical Implementation" scheme="http://qpchen.tk/tags/Physical-Implementation/"/>
    
  </entry>
  
  <entry>
    <title>[Paper] RAMP: Resource-Aware Mapping for CGRAs</title>
    <link href="http://qpchen.tk/2019/07/16/2019-07-16-Paper-RAMP/"/>
    <id>http://qpchen.tk/2019/07/16/2019-07-16-Paper-RAMP/</id>
    <published>2019-07-16T09:58:59.000Z</published>
    <updated>2019-07-18T15:07:26.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>针对当前映射操作依赖到布线资源的策略，都是在调度后阶段，即P&amp;R（Placement and Routing）阶段内调整布线方法，而没有重新调度全图，导致不能映射成功或者质量低下。<br>该文则提出在调度前针对三类未能映射的失败情况，在多个备选布线策略中进行选择，再依据新策略重新调度DDG，最后P&amp;R。成功在映射质量、可映射数量以及求解速度方面得到全面提升。</p><a id="more"></a><h2 id="团队"><a href="#团队" class="headerlink" title="团队"></a>团队</h2><h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>现今各种的映射方法中，不同类型布线策略的最佳模型，均为备选策略。其中作为比较的，主要是寄存器感知和内存感知两种策略的模型。</p><h2 id="贡献和动机"><a href="#贡献和动机" class="headerlink" title="贡献和动机"></a>贡献和动机</h2><p>提出一种新的映射步骤，在原两步映射的前面，加入一个新的布线策略选择步骤。</p><ul><li>该方式既能针对不同的映射失败情况，选择最能利用资源的布线策略，提高映射质量；</li><li>又能实现布线策略修改后的重新调度，从而提高映射成功率；</li><li>另外模拟通用编译器，新提出一个利用其他PE上分布式寄存器组来布线的策略，当该策略失败再选择利用内存来布线的策略，进一步提高质量。</li></ul><p>总而言之，有点像一个集大成的工作，融合了现存各类映射方法。具体是以明确的选择方式，针对不同的情况，选择较优的策略为每个不能映射的依赖做重新映射，从而有针对性的避免各个方法的缺点，实现只取各类方法的优势，避免短板。</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>针对每个不能映射的依赖，分析失败类型，分为以下三种：</p><ol><li>依赖的前置操作和后置操作被调度在长距离时间（distant timing）；而单个寄存器组不能映射过长的依赖；</li><li>依赖的前置操作是一个正在操作的（live-in）或者只读（read-only）值；</li><li>依赖的前置操作和后置操作被调度在结果时间（consequent timing）；因为连线资源不够或者空余PE不足，因此不能映射该依赖；</li></ol><p>针对上述三种类型，分别选择下图中某个或者某些布线策略进行重新调度和P&amp;R尝试，再在选择的策略的映射结果中选择最好的。</p><img src="https://qpimg.ml/images/2019/07/16/A-High-Level-Overview-of-RAMP.png" width="500" title="A High-Level Overview of RAMP"><p>其中各个策略的简单示例如下图所示。</p><p><img src="https://qpimg.ml/images/2019/07/16/Examples-of-Routing-Strategies-in-RAMP.png" alt="Examples_of_Routing_Strategies" title="Examples of Routing Strategies in RAMP"></p><!-- writing here --><!-- ![Alt_text](site "Title") --><!-- <img class="site 500 Title"> --><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><blockquote><p>[1] $Reference (Sites: <a href="$site" title="[1] $[Paper] RAMP: Resource-Aware Mapping for CGRAs">$Publisher</a>) <a href="#简介">Back</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;针对当前映射操作依赖到布线资源的策略，都是在调度后阶段，即P&amp;amp;R（Placement and Routing）阶段内调整布线方法，而没有重新调度全图，导致不能映射成功或者质量低下。&lt;br&gt;该文则提出在调度前针对三类未能映射的失败情况，在多个备选布线策略中进行选择，再依据新策略重新调度DDG，最后P&amp;amp;R。成功在映射质量、可映射数量以及求解速度方面得到全面提升。&lt;/p&gt;
    
    </summary>
    
      <category term="Reconfigurable Computing" scheme="http://qpchen.tk/categories/Reconfigurable-Computing/"/>
    
    
      <category term="CGRA" scheme="http://qpchen.tk/tags/CGRA/"/>
    
      <category term="Mapping" scheme="http://qpchen.tk/tags/Mapping/"/>
    
      <category term="Routing Strategy" scheme="http://qpchen.tk/tags/Routing-Strategy/"/>
    
  </entry>
  
  <entry>
    <title>[Paper] CGRA Express: Accelerating Execution using Dynamic Operation Fusion</title>
    <link href="http://qpchen.tk/2019/07/13/2019-07-13-Paper-CGRA-Express/"/>
    <id>http://qpchen.tk/2019/07/13/2019-07-13-Paper-CGRA-Express/</id>
    <published>2019-07-13T21:06:36.000Z</published>
    <updated>2019-07-18T15:07:26.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>CGRA硬件是一组FU由某种风格的稀疏网络连接，并提供分布式寄存器组。FU提供通用整数操作，包括加减乘。相对于FPGA，其特性是提供门级别的可编程性，因此重构时间较短，且时延和能耗也较少。<br>因为CGRA可编程，对应的有效编译系统则很重要。编译的主要挑战是指令调度。其调度的挑战则是稀疏的网络连接和分布式的寄存器组。CGRA上没有专用的布线资源，而是由FU在某个给定时刻被选择实现计算或者布线资源二者之一的功能。<br>CGRA编译器大多集中在映射计算密集型最内层循环到计算阵列上。但对于latency-constrained code并不删除处理，包括非循环、外层循环和形成环的内层循环的代码。</p><a id="more"></a><h2 id="团队"><a href="#团队" class="headerlink" title="团队"></a>团队</h2><p>密歇根大学（University of Michigan）的Scott Mahlke组，论文当时是Advanced Computer Architecture Laboratory实验室，但现在似乎搜索不到该实验室了。</p><h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>CCA是类似的方法，但是不能覆盖所有的不可加速代码的情况。</p><h2 id="贡献和动机"><a href="#贡献和动机" class="headerlink" title="贡献和动机"></a>贡献和动机</h2><p>AAC Benchmark中线性代码相对于循环代码的运行时间，占用了60%以上。因此加速线性代码以及不能软件流水化的循环代码是很重要的。而之前的相关研究并不能覆盖所有的不能直接加速代码的情况。因此本文提出动态操作融合方法，并给出支持该方法的硬件，最后给出实验评估。</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>假设在同一时钟周期中可以同时执行多个存储和计算操作，利用动态操作融合方法将操作通过旁路网络融合在同一个时钟周期内执行，从而缩短整个应用的执行时间。<br>因此该方法核心在于：</p><ul><li>分析一个时钟周期内可以执行多少操作：<ul><li>通过测算实例内所有操作种类的时延，以及时钟周期。所有的操作的时延均不超过时钟周期的一半；</li><li>依据结果，建立新的单元叫tick，每个tick时延为0.25ns，用于调度。（切分时钟周期）</li></ul></li><li>设计FU中的旁路网络：<ul><li>在FU的输出寄存器后加一个二输入的多路器，能够从FU直接输出值和寄存器中选择值作为最终输出，从而降低融合时FU的时延；</li><li>代价则是控制流的增加，但仅3%左右。（类似极细的存储优化吗？）</li></ul></li><li>基于上述设计优化调度算法</li></ul><p>结果是对于整体测试应用，有7%-17%的执行时间提升，15%的能耗减少。</p><!-- writing here --><!-- ![Alt_text](site "Title") --><!-- <img class="site 500 Title"> --><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><blockquote><p>[1] $Reference (Sites: <a href="$site" title="[1] $[Paper] CGRA Express: Accelerating Execution using Dynamic Operation Fusion">$Publisher</a>) <a href="#简介">Back</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;CGRA硬件是一组FU由某种风格的稀疏网络连接，并提供分布式寄存器组。FU提供通用整数操作，包括加减乘。相对于FPGA，其特性是提供门级别的可编程性，因此重构时间较短，且时延和能耗也较少。&lt;br&gt;因为CGRA可编程，对应的有效编译系统则很重要。编译的主要挑战是指令调度。其调度的挑战则是稀疏的网络连接和分布式的寄存器组。CGRA上没有专用的布线资源，而是由FU在某个给定时刻被选择实现计算或者布线资源二者之一的功能。&lt;br&gt;CGRA编译器大多集中在映射计算密集型最内层循环到计算阵列上。但对于latency-constrained code并不删除处理，包括非循环、外层循环和形成环的内层循环的代码。&lt;/p&gt;
    
    </summary>
    
      <category term="Reconfigurable Computing" scheme="http://qpchen.tk/categories/Reconfigurable-Computing/"/>
    
    
      <category term="CGRA" scheme="http://qpchen.tk/tags/CGRA/"/>
    
      <category term="Operation Fusion" scheme="http://qpchen.tk/tags/Operation-Fusion/"/>
    
  </entry>
  
  <entry>
    <title>[Paper] (RAMS) Recurrence Cycle Aware Modulo Scheduling for Coarse-Grained Reconfigurable Architectures</title>
    <link href="http://qpchen.tk/2019/06/28/2019-06-28-Paper-RAMS/"/>
    <id>http://qpchen.tk/2019/06/28/2019-06-28-Paper-RAMS/</id>
    <published>2019-06-28T10:55:39.000Z</published>
    <updated>2019-07-18T15:07:26.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>该文基于EMS方法，将属于同一个重复环（recurrence cycle）【怎么翻译？】<sup><a href="#fn_RecMII" id="reffn_RecMII">RecMII</a></sup>的操作集中到一个聚合节点（clustered node）上，然后调度这些聚合节点。【这是类似Packing的思路吗？】<br>死锁（Deadlock）会在两个或者更多的recurrence cycle互相依赖时产生【形成环？】。使用启发式方法延长循环时延来解决死锁【具体怎么做的？】。<br>之前的工作需要权衡编译速度和结果质量，而该文的重复环感知方法则无须做这种权衡。</p><p>本文工作也是实现在他们自己的CGRA芯片和编译器解决方案中的，而调度结果的质量和速度均比基于模拟退火（simulated annealing, SA）的方法好。</p><a id="more"></a><blockquote id="fn_RecMII"><sup>RecMII</sup>. 受在当次迭代中仍然需要依赖的上一个迭代中的操作对象（operands）影响，限制II取更小值的限制之一。<a href="#reffn_RecMII" title="Jump back to footnote [RecMII] in the text."> &#8617;</a></blockquote><h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><ul><li>DRESC编译架构中使用基于模拟退火的模调度<ul><li>先初始化一个调度，此时仅考虑操作依赖，而不考虑资源冲突</li><li>第二步调度器随机在FU之间移动操作，直到发现一个有效的调度</li><li>该方法可以取得较好的结果，但是太耗时</li></ul></li><li>EMS集中在操作对象的布线，而不是操作的布局<ul><li>调度时间大量减少</li><li>但调度质量没有DRESC好</li><li>该文分析质量下降的主要原因是重复环中操作的投机调度</li></ul></li><li>把操作集中起来再布局到FU中，并不是该文首创</li></ul><p>从前人工作中，可以看出其idea一般源于两类方向，</p><ul><li>一类是针对调度单个迭代时产生的问题，<ul><li>有方法层面的，例如增加计算资源利用率，包括：在调度时先集中操作再做布局，最后再布线；还有使用图着色算法等；</li><li>也有硬件层面的，例如在调度中降低内存瓶颈、考虑连线时延等，包括建立操作树；将内部连线的时延和数量加入代价函数（cost function）；</li><li>还有直接设计架构或者针对特定调度方法微调架构等。</li></ul></li><li>另一类则是直接针对模调度算法<ul><li>引入模拟退火作为调度算法，但编译太耗时，耗费甚至可能超过几天的时间；</li><li>在基于SA方法的中实现资源感知的布局方法，一定程度减少时间，但仍旧不能接受；</li><li>使用经典图嵌入方法来映射DFG到硬件三维图表示中；</li><li>以边为中心的模调度（edge- centric modulo scheduling, EMS）框架，集中在数据的操作对象（operands）的布线上，而不是数据的操作方式（operations）；</li></ul></li></ul><h2 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h2><ul><li>一个重复环感知的模调度技术，来移除调度中的非必须限制。</li><li>一个架构的微小改进，来显著提高调度质量。【软硬件协同设计？】</li></ul><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><p>EMS可以在局部对每个操作及其操作对象对布局布线产生快速有效对调度，但不能对全局的操作的调度顺序提供一个解决方案。现存EMS是基于操作在DFG中的高度（height）作为顺序的。而如果是调度一个重复环中的操作，则可能未考虑其生产者，先行局部调度。这就在调度中造成了非必须的约束，因为生产者需要与消费者在同一个II周期内，从而导致II的提升，影响调度质量。</p><p>换句话说，一旦一个重复环内的操作被调度，从而固定了调度时刻，则所有周期内的其他操作就被绑定在了该时刻。例如对下图中左边的数据流图映射到右边的架构中的过程进行调度。</p><img src="https://qpimg.ml/images/2019/07/01/example-of-recurrence-cycle-and-simplified-architecture.png" width="500" title="Example of recurrence cycle and simplified architecture"><p>按DFG中高度来算优先级的话，会产生如下图的调度过程。没有输入的1，2，4，6是最高优先的，而仅有一个输入边的7也是最优先调度的操作之一。按该顺序开始调度，则会卡在下图的时刻4，因为没有多余的计算资源以供操作9使用。由于7被绑定在时刻3，重复环的时间限制则会要求操作10和11被调度到时刻4和5中。而操作9因为时刻3中没有可用的布线资源，也需要在时刻4中布局，和操作10分配仅剩的一个空余slot。</p><img src="https://qpimg.ml/images/2019/07/01/scheduling-process-is-stuck-by-recurrence-cycle.png" width="500" title="Scheduling process is stuck by recurrence cycle"><h2 id="重复环感知的CGRA映射"><a href="#重复环感知的CGRA映射" class="headerlink" title="重复环感知的CGRA映射"></a>重复环感知的CGRA映射</h2><p>该方法的核心是一个智能操作排序策略，考虑重复环之间的关系，从而克服上述问题。</p><p>该方法先把重复环打包到一个聚合节点中，当作DFG中的单个节点。然后把其中的操作一起调度。对上述示例的打包如下图所示。该步骤其实对输入DFG进行了转换，形成了一个无环图，并重新计算高度，而该转换是解决上述问题的核心。</p><img src="https://qpimg.ml/images/2019/07/01/Group-recurrence-cycle.png" width="300" title="Group recurrence cycle"><p>这样，重复环的所有生产者操作都会被先行调度，不管环中的操作优先级是不是更高。而当某个重复环代表的聚合节点的所有生产者都被调度后，无视优先级立即对聚合节点进行调度。重复环越早调度越好，因为此时资源尚未被太多占用。上述示例的调度结果如下图所示。</p><img src="https://qpimg.ml/images/2019/07/01/Successful-schedule.png" width="500" title="Successful schedule"><h2 id="硬件架构修改"><a href="#硬件架构修改" class="headerlink" title="硬件架构修改"></a>硬件架构修改</h2><p>修改RF的连接方式，如下图所示，从而增加值可传递的范围，增加了可调度的可能性，但也增加了长距离通信的时延，不过从结果看是有好处的。</p><img src="https://qpimg.ml/images/2019/07/01/CGRA-architecture-modification.png" width="300" title="CGRA architecture modification"><h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><img src="https://qpimg.ml/images/2019/07/01/Comparison-of-the-scheduling-quality.png" width="700" title="Comparison of the scheduling quality"><img src="https://qpimg.ml/images/2019/07/01/Comparison-of-the-compilation-time.png" width="700" title="Comparison of the compilation time"><!-- Writing Here --><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><blockquote><p>[1] Oh, Taewook, Bernhard Egger, Hyunchul Park, and Scott Mahlke. “Recurrence cycle aware modulo scheduling for coarse-grained reconfigurable architectures.” In Proceedings of the 2009 ACM SIGPLAN/SIGBED conference on Languages, compilers, and tools for embedded systems (LCTES ‘09), pp. 21-30. ACM, 2009. (Sites: <a href="https://dl.acm.org/citation.cfm?id=1542456" title="[1] Recurrence Cycle Aware Modulo Scheduling for Coarse-Grained Reconfigurable Architectures" target="_blank" rel="noopener">ACM</a>) <a href="#简介">Back</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;该文基于EMS方法，将属于同一个重复环（recurrence cycle）【怎么翻译？】&lt;sup&gt;&lt;a href=&quot;#fn_RecMII&quot; id=&quot;reffn_RecMII&quot;&gt;RecMII&lt;/a&gt;&lt;/sup&gt;的操作集中到一个聚合节点（clustered node）上，然后调度这些聚合节点。【这是类似Packing的思路吗？】&lt;br&gt;死锁（Deadlock）会在两个或者更多的recurrence cycle互相依赖时产生【形成环？】。使用启发式方法延长循环时延来解决死锁【具体怎么做的？】。&lt;br&gt;之前的工作需要权衡编译速度和结果质量，而该文的重复环感知方法则无须做这种权衡。&lt;/p&gt;
&lt;p&gt;本文工作也是实现在他们自己的CGRA芯片和编译器解决方案中的，而调度结果的质量和速度均比基于模拟退火（simulated annealing, SA）的方法好。&lt;/p&gt;
    
    </summary>
    
      <category term="Reconfigurable Computing" scheme="http://qpchen.tk/categories/Reconfigurable-Computing/"/>
    
    
      <category term="CGRA" scheme="http://qpchen.tk/tags/CGRA/"/>
    
      <category term="Architecture" scheme="http://qpchen.tk/tags/Architecture/"/>
    
      <category term="Modulo Scheduling" scheme="http://qpchen.tk/tags/Modulo-Scheduling/"/>
    
      <category term="EMS" scheme="http://qpchen.tk/tags/EMS/"/>
    
      <category term="Recurrence Cycle" scheme="http://qpchen.tk/tags/Recurrence-Cycle/"/>
    
  </entry>
  
  <entry>
    <title>[Paper] Design Methodology for a Tightly Coupled VLIW/Reconfigurable Matrix Architecture: A Case Study</title>
    <link href="http://qpchen.tk/2019/06/21/2019-06-24-Paper-Case-Study-for-ADRES/"/>
    <id>http://qpchen.tk/2019/06/21/2019-06-24-Paper-Case-Study-for-ADRES/</id>
    <published>2019-06-21T10:47:44.000Z</published>
    <updated>2019-07-18T15:07:26.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><a href="https://dl.acm.org/citation.cfm?id=969178" title="[1] Design methodology for a tightly coupled VLIW/reconfigurable matrix architecture: A case study" target="_blank" rel="noopener">该文章</a>发表在2004年DATE会议上。主要工作是基于他们之前提出的模调度算法和对应的VLIW与CGRA紧密集成的新架构，提出的一个针对MPEG-2解码器应用的基于C的设计流案例，以此说明他们的设计方法能够完整映射一个应用到可重构系统中，并取得预期的堪比直接软件开发的性能。需要注意整个应用一般包含决定时间的规则化代码段和大量非规则的控制密集型代码，决定时间的往往是循环。考虑到应用代码的两个部分，一般硬件架构设计成由一个可重构阵列和一个处理器组成的架构（可将循环映射到阵列上加速，而控制密集型代码由处理器执行），处理器往往是一个RISC。其实这样的架构/系统设计是类似于软硬件协同设计问题的。</p><a id="more"></a><h2 id="Research-Team"><a href="#Research-Team" class="headerlink" title="Research Team"></a>Research Team</h2><h3 id="Team-Informations"><a href="#Team-Informations" class="headerlink" title="Team Informations"></a>Team Informations</h3><p>该论文的主要研究者与2002年FPT上DRESC (Dynamically Reconfigurable Embedded System Compiler) 和2003年FPL上ADRES (Architecture for Dynamic Reconfigurable Embedded Systems) 的主要研究者是同一拨人。</p><h3 id="Previous-Related-Works"><a href="#Previous-Related-Works" class="headerlink" title="Previous Related Works"></a>Previous Related Works</h3><h4 id="一套编译系统：DRESC"><a href="#一套编译系统：DRESC" class="headerlink" title="一套编译系统：DRESC"></a><a href="https://ieeexplore.ieee.org/abstract/document/1188678/" title="[2] DRESC: A retargetable compiler for coarse-grained reconfigurable architectures" target="_blank" rel="noopener">一套编译系统：DRESC</a></h4><p>【这是一套针对CGRA的编译系统？】<sup><a href="#fn_Questions" id="reffn_Questions">Questions</a></sup></p><h4 id="一个新的架构：ADRES"><a href="#一个新的架构：ADRES" class="headerlink" title="一个新的架构：ADRES"></a><a href="https://link.springer.com/chapter/10.1007/978-3-540-45234-8_7" title="[3] ADRES: An architecture with tightly coupled VLIW processor and coarse-grained reconfigurable matrix" target="_blank" rel="noopener">一个新的架构：ADRES</a></h4><p>这是一个超长指令字（Very Long Instruction Word, VLIW）和可重构阵列（reconfigurable matrix）紧密连接的架构模板（template）。区别于松散连接的精简指令集（Reduced Instruction Set Computing, RISC）和可重构阵列架构，ADRES取得了一些优势。【哪些优势？】<sup><a href="#fn_Questions" id="reffn_Questions">Questions</a></sup></p><h4 id="新的模调度算法"><a href="#新的模调度算法" class="headerlink" title="新的模调度算法"></a><a href="https://ieeexplore.ieee.org/document/1253623" title="[4] Exploiting loop-level parallelism for coarse-grained reconfigurable architecture using modulo scheduling" target="_blank" rel="noopener">新的模调度算法</a></h4><p>2003年DATE的一篇文章，提出一个新的模调度算法，用于他们提出的ADRES架构。【是否集成在DRESC中？】<sup><a href="#fn_Questions" id="reffn_Questions">Questions</a></sup></p><h2 id="硬件架构：ADRES-Architecture-Overview"><a href="#硬件架构：ADRES-Architecture-Overview" class="headerlink" title="硬件架构：ADRES Architecture Overview"></a>硬件架构：ADRES Architecture Overview</h2><p>ADRES架构的整体系统结构如下图所示，类似于一个处理器，其执行核心（core）与【分级存储器？】<sup><a href="#fn_Questions" id="reffn_Questions">Questions</a></sup>（memory hierarchy）相连。<br><!-- ![ADRES system](https://qpimg.ml/images/2019/06/21/ADRES-system.png "ADRES system") --><br><img src="https://qpimg.ml/images/2019/06/21/ADRES-system.png" width="200" title="ADRES system"></p><p>系统中的ADRES核心如下图所示，包含诸多组件，例如：【功能单元？】（Function Units, FUs）and 【寄存器组？】（register files, RF）。<sup><a href="#fn_Questions" id="reffn_Questions">Questions</a></sup><br><!-- ![ADRES core](https://qpimg.ml/images/2019/06/21/ADRES-core.png "ADRES core") --><br><img src="https://qpimg.ml/images/2019/06/21/ADRES-core-with-dark-share-view.png" width="600" title="ADRES core"></p><p>该核心有两个功能区域，这两个区域共享一些资源，如上图阴影部分所示，但因为【处理器/协处理器？】<sup><a href="#fn_Questions" id="reffn_Questions">Questions</a></sup>（processor/co-processor）模型，这两个区域在执行时永远不会在共享资源上有重叠。这两部分分别为：</p><ul><li>超长指令字处理器：利用指令级并行（instruction-level parallelism, ILP）执行无计算内核（kernel）的代码。</li></ul><p>这是一个典型的VLIW架构，分配一些FU，并用一个多端口（port）的RF将它们连接起来。而这些FU还能通过可用的端口与memory hierarchy相连。</p><ul><li>可重构阵列：用高并行度的方式加速类数据流（dataflow-like）计算内核（kernel）。</li></ul><p>除了与VLIW处理器共享的FU和RF部分，可重构阵列部分还有一些包含了FU和RF的可重构单元（reconfigurable cells, RC），其构造如下图所示。</p><!-- ![Reconfigurable Cell](https://qpimg.ml/images/2019/06/21/Reconfigurable-Cell.png "Reconfigurable Cell") --><img src="https://qpimg.ml/images/2019/06/21/Reconfigurable-Cell.png" width="350" title="Reconfigurable Cell"><ul><li>FU可以是异构的，来支持不同的操作集。为了从循环（loop）中分离出控制流，FU支持预测操作（predicted operation）。</li><li>多路器（multiplexors）用于和其他资源数据直连。</li><li>配置存储器（configuration RAM）则本地（locally）存储一些【配置文本？】（configuration contexts）<sup><a href="#fn_Questions" id="reffn_Questions">Questions</a></sup>。<ul><li>配置环境可以在每个周期（cycle-by-cycle）从配置存储器中被循环读取。</li><li>当本地配置存储器不够大时，配置环境也可以从memory hierarchy中读取，但会造成额外的延迟开销。</li></ul></li><li>存储的共享（share）用于支持VLIW处理器与可重构阵列之间的通信，例如RF和memory hierarchy的共享。</li></ul><p>ADRES的VLIW和可重构阵列紧密连接架构的优势：</p><ol><li>用VLIW能够加速非计算内核代码（non-kernel code），这些代码也往往是很多应用的瓶颈，而RISC不行；</li><li>通过RF和内存存储的共享极大的降低了通信开销和编程复杂度；</li><li>共享的资源能够极大降低【资源？】<sup><a href="#fn_Questions" id="reffn_Questions">Questions</a></sup>开销（costs）</li></ol><h2 id="基于C的设计流"><a href="#基于C的设计流" class="headerlink" title="基于C的设计流"></a>基于C的设计流</h2><p>ADRES的设计流如下图所示：</p><!-- ![Design flow for ADRES](https://qpimg.ml/images/2019/06/23/Design-flow-for-ADRES.png "Design flow for ADRES") --><img src="https://qpimg.ml/images/2019/06/23/Design-flow-for-ADRES.png" width="700" title="Design flow for ADRES"><p>一个设计开始于使用C语言描述的应用，作为输入之一引入设计流。上图的右侧则是涉及目标硬件架构的基于XML的描述，作为另一个输入引入设计流。具体描述如下：</p><ul><li>profiling/partitioning：发现候选循环（loop），将在执行期映射到可重构阵列（P.S. 主要依靠人工识别）</li><li>Source-level transformations：重构计算内核（kernel），以允许流水化</li><li>IMPACT：是一个主要针对VLIW的编译器框架，用来语法解析、分析和优化C代码</li><li>Lcode：IMPACT生成的一个中间表示，作为调度（scheduling）的输入</li><li>Architecture：XML描述的语法分析和抽象，转化架构描述为内部图表示</li><li>接受应用程序和硬件表示作为输入，该工具分两个部分进行处理<ul><li>模调度（modulo scheduling）算法使得计算内核能够达到高并行度</li><li>同时传统指令级并行调度使得非内核代码达到中度并行</li></ul></li><li>这两部分的通信由工具发现并提供【是由register allocation部分负责吗？】<sup><a href="#fn_Questions" id="reffn_Questions">Questions</a></sup></li><li>为VLIW和可重构阵列生成调度后代码，可由联合仿真器（co-simulator）进行仿真</li><li>另外一个正在进行的工作是内核调度，当配置存储器（configuration RAM）不能储存所有的内核时，该算法能够降低配置开销</li></ul><p>一个中央配置文件（setting file）控制整个编译过程<sup><a href="#fn_Question1" id="reffn_Question1">Question1</a></sup>，包括整个设计环境和每个单独的循环。因此允许编译器在某一时刻集中关注单个循环，这种策略能降低设计时间，如下图所示。</p><!-- ![Focus-on-one-loop-at-a-time.png](https://qpimg.ml/images/2019/06/23/Focus-on-one-loop-at-a-time.png "Focus on one loop at a time") --><img src="https://qpimg.ml/images/2019/06/23/Focus-on-one-loop-at-a-time.png" width="700" title="Focus on one loop at a time"><ul><li>第一步，针对单个循环<em>loop1</em>，先进行源代码级转换输出<em>loop1*</em>，并由VLIW进行验证。这一步的用时极少；</li><li>第二步，则是对<em>loop1*</em>进行模调度，该文中的模调度算法类似一个布局布线算法，但仍然很耗时；<ul><li>模调度尝试找到一个调度，拥有尽量小的【启动间距？】（initiation interval, II）<sup><a href="#fn_Questions" id="reffn_Questions">Questions</a></sup>，即便II只有1的差距，也会造成很大影响；</li><li>为了找到一个更小的II，值得耗时进行多次尝试，而如果模调度始终找不到好的解决方案，就返回源码级转换进行更多改进，直到找到一个合适的调度；</li></ul></li><li>接着，暂存<em>loop1*</em>的映射到VLIW；</li><li>返回第一步迭代处理<em>loop2</em>，直到所有的循环均成果映射到可重构阵列上进行加速；</li><li>最后多个循环能被中央setting file整合起来，而不会发生特殊情况造成结果不确定。</li></ul><p>这种设计策略的有点包括，能够使焦点专注于单个循环的映射，且每个循环能够被co-simulator验证，且对并行化设计流很有帮助。<br>而两个硬件部分VLIW和可重构阵列之间的通信，也因为紧密的硬件架构，变得能够依靠编译器自动化进行，且开销很小。仅需识别两部分需要产生和消耗的实时变量，并将其存入共享RF（VLIW RF）中即可，而通过内存空间的通信则更无须特别做什么，这两部分共享内存访问。</p><h2 id="MPEG-2解码器映射案例"><a href="#MPEG-2解码器映射案例" class="headerlink" title="MPEG-2解码器映射案例"></a>MPEG-2解码器映射案例</h2><p>MPEG-2解码器是一个多媒体领域的应用，需要很高的计算能耗。其大多执行时间消耗在若干计算内核（kernel）上，因此很适合用可重构架构来运行。该案例使用一个C实现的实例，源自MPEG Software Simulation Group (MSSG)。该实现的代码对处理器高度优化过，且是MediaBench的一部分。整个应用包含21个文件，共一万行左右代码。</p><h3 id="映射到ADRES架构"><a href="#映射到ADRES架构" class="headerlink" title="映射到ADRES架构"></a>映射到ADRES架构</h3><ul><li>profiling：人工识别到应用中有14处循环（loop），作为可重构阵列的流水候选。另外，为了进一步提升性能，该文作者还从VLD(variable length decoding)循环中抽取出2个去量化循环，用于在可重构阵列中加速，如下图所示。所有16处循环占总执行时间的84.6%，却仅占总代码量的3.3%。</li></ul><img src="https://qpimg.ml/images/2019/06/24/Extract-intra-dequant-loop.png" width="500" title="Extract intra dequant loop"><ul><li>source-level transformation：除了少部分能直接映射的循环，其余需要先进行循环转换。<ul><li>例如下图中IDCT（inverse dis- crete cosine transformation）计算内核，其内层循环体，是一个函数，因此对于可重构阵列是不可流水化的。<ul><li>首先把循环体函数（图中的idctrow）的操作放入循环内</li><li>接着把非规则计算（图中的shortcut）移除，使得循环更规则化</li><li>最后把idct应用到一个微块上，使其符合硬件8x8的尺寸。对于MPEG-2视频一般使用6个8x8到块，也使得原来的8次迭代增加到64次迭代，极大降低了流水开支<sup><a href="#fn_question2" id="reffn_question2">question2</a></sup>。</li></ul></li><li>对于其他的不易流水化的循环，还有更多的转换方法，<ul><li>例如循环展开（loop unrolling）、【循环扁平化？】（loop flattening）、【变量复制？】（variable replicating）等<sup><a href="#fn_Questions" id="reffn_Questions">Questions</a></sup></li><li>但这些到目前（2004年）都需要根据设计者的经验来选择合适的。</li><li>该文作者使用3天来完成应用程序中这些循环的C到C改写，实现循环转换。</li></ul></li></ul></li></ul><img src="https://qpimg.ml/images/2019/06/24/Transformation-for-idct1-loop.png" width="500" title="Transformation for idct1 loop"><p>当所有循环都被工具成功映射后，可以为每个循环获取其配置context。</p><p>而当MPEG-2应用到输入视频，改变大小时，循环数量会相应增加，导致配置存储器可能不够，因此该文正在解决的技术是内核调度技术。</p><h3 id="映射实验结果"><a href="#映射实验结果" class="headerlink" title="映射实验结果"></a>映射实验结果</h3><p>为了做实验，使用来一个类似MorphoSys的硬件实例作为ADRES模板的实现。</p><ul><li>总共64个FU，被分为四片（tile），每片包含4x4的FU；</li><li>每个FU除了能连接相邻4个FU，还可以连接所有同一tile中的同行和同列FU，另外整个阵列还有行总线和列总线；</li><li>第一行FU能够被VLIW处理器使用，并连接到一个多端口寄存器组上；</li><li>只有第一行的FU能够执行内存操作，例如load/store操作。</li></ul><p>实验结果如下图所示，第四列是Instruction-per-cycle（IPC）；第五列是total pipeline stages。第六列调度时间是在Pentium 4 1.7GHz/Linux PC平台上运行的CPU时间。</p><img src="https://qpimg.ml/images/2019/06/24/Scheduling-results-for-kernels.png" width="400" title="Scheduling results for kernels"><p>【上述图示均为<a href="https://dl.acm.org/citation.cfm?id=969178" title="[1] Design methodology for a tightly coupled VLIW/reconfigurable matrix architecture: A case study" target="_blank" rel="noopener">文中</a>图片，有待重画】<sup><a href="#fn_Questions" id="reffn_Questions">Questions</a></sup></p><blockquote id="fn_Questions"><sup>Questions</sup>. 用【】框起来的内容为尚未确定或者待解决的问题<a href="#reffn_Questions" title="Jump back to footnote [Questions] in the text."> &#8617;</a></blockquote><blockquote id="fn_Question1"><sup>Question1</sup>. 【是不是存储在中央寄存器组中？因为该硬件与这个文件的属性很相符】<a href="#reffn_Question1" title="Jump back to footnote [Question1] in the text."> &#8617;</a></blockquote><blockquote id="fn_question2"><sup>question2</sup>. 流水开支是指？怎么降低流水开支的？<a href="#reffn_question2" title="Jump back to footnote [question2] in the text."> &#8617;</a></blockquote><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><blockquote><p>[1] Mei, Bingfeng, Serge Vernalde, Diederik Verkest, and Rudy Lauwereins. “Design methodology for a tightly coupled VLIW/reconfigurable matrix architecture: A case study.” In Proceedings of the conference on Design, automation and test in Europe-Volume 2, p. 21224. IEEE Computer Society, 2004. (Sites: <a href="https://dl.acm.org/citation.cfm?id=969178" title="[1] Design methodology for a tightly coupled VLIW/reconfigurable matrix architecture: A case study" target="_blank" rel="noopener">IEEE</a>) <a href="#Introduction">Back</a><br>[2] Mei, Bingfeng, Serge Vernalde, Diederik Verkest, Hugo De Man, and Rudy Lauwereins. “DRESC: A retargetable compiler for coarse-grained reconfigurable architectures.” In 2002 IEEE International Conference on Field-Programmable Technology, 2002.(FPT). Proceedings., pp. 166-173. IEEE, 2002. (Sites: <a href="https://ieeexplore.ieee.org/abstract/document/1188678/" title="[2] DRESC: A retargetable compiler for coarse-grained reconfigurable architectures" target="_blank" rel="noopener">IEEE</a>) <a href="#一套编译系统：DRESC">Back</a><br>[3] Mei, Bingfeng, Serge Vernalde, Diederik Verkest, Hugo De Man, and Rudy Lauwereins. “ADRES: An architecture with tightly coupled VLIW processor and coarse-grained reconfigurable matrix.” In International Conference on Field Programmable Logic and Applications, pp. 61-70. Springer, Berlin, Heidelberg, 2003. (Sites: <a href="https://link.springer.com/chapter/10.1007/978-3-540-45234-8_7" title="[3] ADRES: An architecture with tightly coupled VLIW processor and coarse-grained reconfigurable matrix" target="_blank" rel="noopener">Springer</a>) <a href="#一个新的架构：ADRES">Back</a><br>[4] Mei, Bingfeng, Serge Vernalde, Diederik Verkest, Hugo De Man, and Rudy Lauwereins. “Exploiting Loop-Level Parallelism on Coarse-Grained Reconfigurable Architectures Using Modulo Scheduling.” In Proceedings of the conference on Design, Automation and Test in Europe-Volume 1, p. 10296. IEEE Computer Society, 2003. (Sites: <a href="https://ieeexplore.ieee.org/document/1253623" title="[4] Exploiting loop-level parallelism for coarse-grained reconfigurable architecture using modulo scheduling" target="_blank" rel="noopener">IEEE</a>) <a href="#新的模调度算法">Back</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://dl.acm.org/citation.cfm?id=969178&quot; title=&quot;[1] Design methodology for a tightly coupled VLIW/reconfigurable matrix architecture: A case study&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;该文章&lt;/a&gt;发表在2004年DATE会议上。主要工作是基于他们之前提出的模调度算法和对应的VLIW与CGRA紧密集成的新架构，提出的一个针对MPEG-2解码器应用的基于C的设计流案例，以此说明他们的设计方法能够完整映射一个应用到可重构系统中，并取得预期的堪比直接软件开发的性能。需要注意整个应用一般包含决定时间的规则化代码段和大量非规则的控制密集型代码，决定时间的往往是循环。考虑到应用代码的两个部分，一般硬件架构设计成由一个可重构阵列和一个处理器组成的架构（可将循环映射到阵列上加速，而控制密集型代码由处理器执行），处理器往往是一个RISC。其实这样的架构/系统设计是类似于软硬件协同设计问题的。&lt;/p&gt;
    
    </summary>
    
      <category term="Reconfigurable Computing" scheme="http://qpchen.tk/categories/Reconfigurable-Computing/"/>
    
    
      <category term="ADRES" scheme="http://qpchen.tk/tags/ADRES/"/>
    
      <category term="CGRA" scheme="http://qpchen.tk/tags/CGRA/"/>
    
      <category term="Case Study" scheme="http://qpchen.tk/tags/Case-Study/"/>
    
      <category term="Modulo Scheduling" scheme="http://qpchen.tk/tags/Modulo-Scheduling/"/>
    
      <category term="VLIW" scheme="http://qpchen.tk/tags/VLIW/"/>
    
  </entry>
  
  <entry>
    <title>[Survey] CGRA</title>
    <link href="http://qpchen.tk/2019/06/14/2019-06-17-Survey-CGRA/"/>
    <id>http://qpchen.tk/2019/06/14/2019-06-17-Survey-CGRA/</id>
    <published>2019-06-14T12:15:12.000Z</published>
    <updated>2019-06-24T10:37:04.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>计算密集型应用的硬件加速往往通过映射技术将密集计算映射（Mapping）到<a href="https://doi.org/10.1109/JPROC.2014.2386883" title="Tessier, R., Pocek, K., &amp; DeHon, A. (2015). Reconfigurable Computing Architectures. Proceedings of the IEEE, 103(3), 332–354." target="_blank" rel="noopener">可重构计算（Reconfigurable Computing, RC）</a>芯片上。而一般而言，应用执行时间主要消耗在少量的循环处。因此，可重构计算芯片上的循环映射优化对于提升计算密集型应用的执行性能具有重要意义。<br>CGRA（Coarse-Grained Reconfigurable Architecture）是一种可重构计算架构，字面翻译为粗粒度可重构处理器。其基础处理单元（Processing Element, PE）为指令级别（Word-Level）的，区别于FPGA（Field Programable Gate Array, 现场可编程门阵列）的门级别，能够直接实现一些典型的逻辑计算。由于CGRA上特殊的硬件结构以及循环程序中语句复杂的依赖关系，CGRA上的循环映射也存在着挑战。</p><a id="more"></a><h2 id="可重构处理器体系结构"><a href="#可重构处理器体系结构" class="headerlink" title="可重构处理器体系结构"></a>可重构处理器体系结构</h2><h3 id="硬件简介及基本属性"><a href="#硬件简介及基本属性" class="headerlink" title="硬件简介及基本属性"></a>硬件简介及基本属性</h3><p>组成：<br>PE组成的Array由一个类mesh风格的内部连线连接起来的架构</p><p>属性：<br>由于大量的资源因此有高吞吐量<br>而分布式的硬件带来低功耗<br>动态可编程则提供高灵活性</p><p>主要参数：<br>大小：PE 数量，一般构成一个正方形的阵列，一般4<em>4～8</em>8，也有32*32<br>互连形式：crossbar；mesh；mesh plus；morphosys……<br>寄存器共享方式：完全分布式；bus行列分布式；中央寄存器式；混合式<br>PE 功能：同构/异构；ALU功能类型；PE动态功能……</p><h3 id="硬件分类"><a href="#硬件分类" class="headerlink" title="硬件分类"></a>硬件分类</h3><p>根据程序运行的过程中阵列的电路结构是否改变，分为：</p><ul><li>静态可重构：如FPGA</li><li>动态可重构：如CGRA</li></ul><p>根据阵列互连形式的不同，CGRA主要分为：</p><ul><li>一维互连CGRA</li><li>二维互连CGRA</li></ul><h2 id="可重构处理器编译技术"><a href="#可重构处理器编译技术" class="headerlink" title="可重构处理器编译技术"></a><a href="http://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CDFD&amp;dbname=CDFDLAST2017&amp;filename=1017800368.nh&amp;v=MDc1MDRHYnU0SHRMS3A1RWJQSVI4ZVgxTHV4WVM3RGgxVDNxVHJXTTFGckNVUkxPZlllZHBGQ3JrVXJ6QlZGMjY=" title="刘大江. 可重构处理器编译系统中循环优化关键技术研究[D].清华大学,2015." target="_blank" rel="noopener">可重构处理器编译技术</a></h2><h3 id="编译对可重构计算的重要性"><a href="#编译对可重构计算的重要性" class="headerlink" title="编译对可重构计算的重要性"></a>编译对可重构计算的重要性</h3><p>由于可重构处理器和通用处理器的硬件结构有很大的不同，可重构处理器编译器的编译流程和生成的可执行文件都有很大的不同。</p><ul><li>通用处理器的编译是将应用程序编译生成单一目标处理器的汇编指令和机器码。</li><li>而可重构处理器编译器则首先要对应用程序进行软硬件划分，把应用程序中适合硬件加速的计算密集型部分划分出来。然后针对两部分分别作编译处理，分别生产运行在主控制器控制码和可重构计算阵列上配置信息。</li></ul><p>因此，我们所熟知的串行编程模式不能够被直接应用在可重构处理器上。可重构处理器编译是一个极具挑战性的工作。如果没 有易用的编译器，编程人员则需要非常熟悉可重构处理器的底层硬件结构来进行 开发。这将大大降低可重构处理器的通用性。因此，可重构处理器编译器对于可 重构处理器具有极为重要的作用。</p><h2 id="CGRA循环映射技术"><a href="#CGRA循环映射技术" class="headerlink" title="CGRA循环映射技术"></a>CGRA循环映射技术</h2><p><strong>为何要针对循环进行映射优化？</strong></p><p>因为在现代实际生活应用程序中(例如:声音、图像处理等应用)，循环往往占据了这些程序的大部分运行时间。循环的特点是多次重复同一个计算内核（Kernel），不改变运算的结构，只改变运算的数据。<a href="http://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CDFD&amp;dbname=CDFDLAST2017&amp;filename=1017800368.nh&amp;v=MDc1MDRHYnU0SHRMS3A1RWJQSVI4ZVgxTHV4WVM3RGgxVDNxVHJXTTFGckNVUkxPZlllZHBGQ3JrVXJ6QlZGMjY=" title="刘大江. 可重构处理器编译系统中循环优化关键技术研究[D].清华大学,2015." target="_blank" rel="noopener">[2]</a></p><p>因此循环映射技术往往是针对从某类应用程序中抽象出的计算内核来进行优化的。</p><h3 id="CGRA映射（Mapping）技术"><a href="#CGRA映射（Mapping）技术" class="headerlink" title="CGRA映射（Mapping）技术"></a>CGRA映射（Mapping）技术</h3><p>根据PE在映射时的功能，可分为两类映射技术：</p><ul><li>空间映射：主要针对一维互连架构</li><li>时域映射：主要针对二维互连架构</li></ul><p>根据可重构计算阵列的<strong>运算模式</strong>，可分为下列两种情况：</p><ul><li>一次配置多次执行：由于少量的配置，可以大大节省配置的开销，从而可以提高性能，降低功耗。</li><li>一次配置一次执行：提高来可配置性，但大大降低可重构处理器的执行性能，功耗也会大大增加。</li></ul><p>总之，降低配置次数对于提高可重构处 理器的性能是非常有帮助的。</p><h4 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h4><ul><li><strong>多层嵌套</strong>循环如何处理，以降低内外循环之间交互的开销，同时保证各个循环之间执行顺序的正确性。</li><li>由于循环间的<strong>数据依赖</strong>，如何在限定的空间资源和时序约束中进行合法的布局布线也是一个难点。<ul><li>选取合适的循环变换可以改变数据依赖的形式，以更好得进行映射，因此如何选择循环变换方法就是一个挑战；</li><li>硬件资源有限，如何充分地利用有限的各类硬件资源对于循环映射也是一个挑战：<ul><li>有限的配置存储资源：如果配置存储资源不够，动态可重构的能力会非常受限。因此，如何在循环映射的时候减少配置代价是一个难点；</li><li>稀疏的计算和互连资源：由于芯片面积和功耗的限制，计算阵列的规模一般不大，且阵列中计算单元之间的互连资源一般也比较稀疏；</li><li>有限的数据存储资源：主要体现在带宽和存储空间上，由于芯片面积和功耗的限制，阵列中只有某些处理单元能够访问数据存储器；</li></ul></li></ul></li></ul><h3 id="调度算法"><a href="#调度算法" class="headerlink" title="调度算法"></a>调度算法</h3><h3 id="布局布线"><a href="#布局布线" class="headerlink" title="布局布线"></a>布局布线</h3>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;摘要&lt;/h2&gt;&lt;p&gt;计算密集型应用的硬件加速往往通过映射技术将密集计算映射（Mapping）到&lt;a href=&quot;https://doi.org/10.1109/JPROC.2014.2386883&quot; title=&quot;Tessier, R., Pocek, K., &amp;amp; DeHon, A. (2015). Reconfigurable Computing Architectures. Proceedings of the IEEE, 103(3), 332–354.&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;可重构计算（Reconfigurable Computing, RC）&lt;/a&gt;芯片上。而一般而言，应用执行时间主要消耗在少量的循环处。因此，可重构计算芯片上的循环映射优化对于提升计算密集型应用的执行性能具有重要意义。&lt;br&gt;CGRA（Coarse-Grained Reconfigurable Architecture）是一种可重构计算架构，字面翻译为粗粒度可重构处理器。其基础处理单元（Processing Element, PE）为指令级别（Word-Level）的，区别于FPGA（Field Programable Gate Array, 现场可编程门阵列）的门级别，能够直接实现一些典型的逻辑计算。由于CGRA上特殊的硬件结构以及循环程序中语句复杂的依赖关系，CGRA上的循环映射也存在着挑战。&lt;/p&gt;
    
    </summary>
    
      <category term="Reconfigurable Computing" scheme="http://qpchen.tk/categories/Reconfigurable-Computing/"/>
    
    
      <category term="CGRA" scheme="http://qpchen.tk/tags/CGRA/"/>
    
      <category term="Architecture" scheme="http://qpchen.tk/tags/Architecture/"/>
    
      <category term="Survey" scheme="http://qpchen.tk/tags/Survey/"/>
    
      <category term="Mapping" scheme="http://qpchen.tk/tags/Mapping/"/>
    
      <category term="Scheduling" scheme="http://qpchen.tk/tags/Scheduling/"/>
    
  </entry>
  
  <entry>
    <title>Compiler Overview</title>
    <link href="http://qpchen.tk/2019/03/06/2019-03-06-Compiler-Overview/"/>
    <id>http://qpchen.tk/2019/03/06/2019-03-06-Compiler-Overview/</id>
    <published>2019-03-06T15:30:58.000Z</published>
    <updated>2019-03-06T14:17:58.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Program-Execution-程序执行"><a href="#Program-Execution-程序执行" class="headerlink" title="Program Execution 程序执行"></a>Program Execution 程序执行</h1><p>计算机程序执行过程主要涉及四个部分，包括<a href="#Code-代码">代码</a>、翻译、中间表示和执行。其中侠义的编译器属于翻译部分，而一个完整的编译系统的执行包含了所有四个部分。</p><a id="more"></a><h2 id="Code-代码"><a href="#Code-代码" class="headerlink" title="Code 代码"></a>Code 代码</h2><p>代码（Code）是指由计算机程序的形式编码而成的一系列指令集合，它能够由计算机执行。在计算机硬件上运行软件需要两个部分，一个是代码（Code），另一个是数据（Data）。</p><p>计算机只能直接执行由指令集中指令构成的机器码（Machine Code）。但不论是机器码还是其他低级程序语言，都不是可以简单阅读的，因此大多源码（Source Code）都是由高级程序语言编写的。而编译器（Compiler）或者解释器（Interpreter）则将源码翻译成计算机可执行的机器语言。一个编译器生成的是目标代码（Object Code），一般来说就是机器语言（Machine Language）构成的，但也包括一些比源码更低级别的中间语言（Intermediate Language）。而解释器则是解释字节码（Bytecode）的工具，字节码是一种比源码低级的代码。</p><p>接下来具体说明代码的不同种类。</p><h3 id="Source-Code"><a href="#Source-Code" class="headerlink" title="Source Code"></a>Source Code</h3><p>任意的使用人类可读的程序语言编写的代码组合都可称为源码（Source Code），它可能包含注释，一般使用富文本表达。源码一般会被汇编器（Assembler）或者编译器（Compiler）翻译成二进制机器码（Binary Machine Code），从而能够直接被计算机理解，这段机器码可能会被存储起来，从而晚一点再执行。除此之外，源码也可能被解释，从而立即执行。</p><h3 id="Object-Code"><a href="#Object-Code" class="headerlink" title="Object Code"></a>Object Code</h3><p>目标代码（Object Code）是编译器的产物。通常来讲，目标码是一段状态或者指令的序列，它是由一种计算机语言表示的，一般是一种机器码语言或者中间语言，例如RTL (Register Transfer Language)就是一种中间语言。</p><h3 id="Bytecode"><a href="#Bytecode" class="headerlink" title="Bytecode"></a>Bytecode</h3><h3 id="Machine-Code"><a href="#Machine-Code" class="headerlink" title="Machine Code"></a>Machine Code</h3><h3 id="Microcode"><a href="#Microcode" class="headerlink" title="Microcode"></a>Microcode</h3><h2 id="Translator-Computing"><a href="#Translator-Computing" class="headerlink" title="Translator (Computing)"></a>Translator (Computing)</h2><h3 id="Compiler"><a href="#Compiler" class="headerlink" title="Compiler"></a>Compiler</h3><h4 id="Compile-time"><a href="#Compile-time" class="headerlink" title="Compile-time"></a>Compile-time</h4><h3 id="Optimizing-Compiler"><a href="#Optimizing-Compiler" class="headerlink" title="Optimizing Compiler"></a>Optimizing Compiler</h3><h2 id="Intermediate-Representation-IR"><a href="#Intermediate-Representation-IR" class="headerlink" title="Intermediate Representation (IR)"></a>Intermediate Representation (IR)</h2><h2 id="Execution"><a href="#Execution" class="headerlink" title="Execution"></a>Execution</h2><h3 id="Runtime-System"><a href="#Runtime-System" class="headerlink" title="Runtime System"></a>Runtime System</h3><h4 id="Runtime"><a href="#Runtime" class="headerlink" title="Runtime"></a>Runtime</h4><h3 id="Executable"><a href="#Executable" class="headerlink" title="Executable"></a>Executable</h3><h3 id="Interpreter"><a href="#Interpreter" class="headerlink" title="Interpreter"></a>Interpreter</h3><h3 id="Virtual-Machine"><a href="#Virtual-Machine" class="headerlink" title="Virtual Machine"></a>Virtual Machine</h3><hr><h1 id="Compilation-Strategies"><a href="#Compilation-Strategies" class="headerlink" title="Compilation Strategies"></a>Compilation Strategies</h1><h2 id="Just-in-Time-JIT"><a href="#Just-in-Time-JIT" class="headerlink" title="Just-in-Time (JIT)"></a>Just-in-Time (JIT)</h2><h3 id="Tracing-Just-in-Time"><a href="#Tracing-Just-in-Time" class="headerlink" title="Tracing Just-in-Time"></a>Tracing Just-in-Time</h3><h2 id="Ahead-of-Time-AOT"><a href="#Ahead-of-Time-AOT" class="headerlink" title="Ahead-of-Time (AOT)"></a>Ahead-of-Time (AOT)</h2><h2 id="Transcompilation"><a href="#Transcompilation" class="headerlink" title="Transcompilation"></a>Transcompilation</h2><h2 id="Recompilation"><a href="#Recompilation" class="headerlink" title="Recompilation"></a>Recompilation</h2>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Program-Execution-程序执行&quot;&gt;&lt;a href=&quot;#Program-Execution-程序执行&quot; class=&quot;headerlink&quot; title=&quot;Program Execution 程序执行&quot;&gt;&lt;/a&gt;Program Execution 程序执行&lt;/h1&gt;&lt;p&gt;计算机程序执行过程主要涉及四个部分，包括&lt;a href=&quot;#Code-代码&quot;&gt;代码&lt;/a&gt;、翻译、中间表示和执行。其中侠义的编译器属于翻译部分，而一个完整的编译系统的执行包含了所有四个部分。&lt;/p&gt;
    
    </summary>
    
      <category term="Compiler" scheme="http://qpchen.tk/categories/Compiler/"/>
    
    
      <category term="Compiler" scheme="http://qpchen.tk/tags/Compiler/"/>
    
      <category term="Overview" scheme="http://qpchen.tk/tags/Overview/"/>
    
  </entry>
  
  <entry>
    <title>CGO Compiler</title>
    <link href="http://qpchen.tk/2019/02/27/2019-02-27-CGO-Compiler/"/>
    <id>http://qpchen.tk/2019/02/27/2019-02-27-CGO-Compiler/</id>
    <published>2019-02-27T17:00:00.000Z</published>
    <updated>2019-04-17T04:11:10.000Z</updated>
    
    <content type="html"><![CDATA[<p>International Symposium on Code Generation and Optimization (CGO) 是和International Symposium on High-Performance Computer Architecture (HPCA)，ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPoPP)，International Conference on Compiler Construction (CC)合作的。</p><p>This is a record of reading about working shop on CGO 19’. The workshop included talks from various projects - Julia (Julia Computing), TVM (UW), Glow (Facebook), XLA (Google), nGraph (Intel), TensorRT (Nvidia), <a href="https://www.xilinx.com/products/design-tools/developer-forum.html" title="xDNN Developer Forum" target="_blank" rel="noopener">xDNN</a> (Xilinx, DeePhi DP(<a href="https://www.xilinx.com/products/design-tools/developer-forum.html)U" target="_blank" rel="noopener">https://www.xilinx.com/products/design-tools/developer-forum.html)U</a>) and the soon to release MLIR (Google).</p><a id="more"></a><h1 id="Workshop-on-Compilers-for-Machine-Learning-C4ML"><a href="#Workshop-on-Compilers-for-Machine-Learning-C4ML" class="headerlink" title="Workshop on Compilers for Machine Learning (C4ML)"></a>Workshop on Compilers for Machine Learning (<a href="https://www.c4ml.org/" title="Compilers for Machine Learning" target="_blank" rel="noopener">C4ML</a>)</h1><h2 id="Julia-A-Compiler-to-compile-Code-from-Julia-to-XLA"><a href="#Julia-A-Compiler-to-compile-Code-from-Julia-to-XLA" class="headerlink" title="Julia: A Compiler to compile Code from Julia to XLA"></a>Julia: A Compiler to compile Code from Julia to XLA</h2><blockquote><p>“Getting to Machine Learning from a General Purpose Compiler”, Keno Fischer, Jameson Nash, <a href="https://juliacomputing.com/communication/publications.html" title="Julia Computing Publications" target="_blank" rel="noopener"><strong>Julia Computing</strong></a>.<br>Presentation: <a href="https://juliacomputing.com/assets/pdf/CGO_C4ML_talk.pdf" title="Julia Presentation" target="_blank" rel="noopener">PDF</a>, <a href="https://juliacomputing.com/blog/2019/02/19/growing-a-compiler.html" title="Julia Blog" target="_blank" rel="noopener">Blog</a></p></blockquote><p>这个编译器的目标是编译Julia代码到TPU平台的XLA代码上，因此编译器的Backend是LLVM。而LLVM是一个静态编译Backend，而Julia语言在语义上是动态语言，因此编译器需要转化原语言中的动态语义到LLVM的静态语义表示。</p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;International Symposium on Code Generation and Optimization (CGO) 是和International Symposium on High-Performance Computer Architecture (HPCA)，ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPoPP)，International Conference on Compiler Construction (CC)合作的。&lt;/p&gt;
&lt;p&gt;This is a record of reading about working shop on CGO 19’. The workshop included talks from various projects - Julia (Julia Computing), TVM (UW), Glow (Facebook), XLA (Google), nGraph (Intel), TensorRT (Nvidia), &lt;a href=&quot;https://www.xilinx.com/products/design-tools/developer-forum.html&quot; title=&quot;xDNN Developer Forum&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;xDNN&lt;/a&gt; (Xilinx, DeePhi DP(&lt;a href=&quot;https://www.xilinx.com/products/design-tools/developer-forum.html)U&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.xilinx.com/products/design-tools/developer-forum.html)U&lt;/a&gt;) and the soon to release MLIR (Google).&lt;/p&gt;
    
    </summary>
    
      <category term="Conference" scheme="http://qpchen.tk/categories/Conference/"/>
    
    
      <category term="Compiler" scheme="http://qpchen.tk/tags/Compiler/"/>
    
      <category term="Record" scheme="http://qpchen.tk/tags/Record/"/>
    
      <category term="Computer Architecture" scheme="http://qpchen.tk/tags/Computer-Architecture/"/>
    
  </entry>
  
  <entry>
    <title>Domain Specific Words</title>
    <link href="http://qpchen.tk/2019/02/25/2019-02-25-Domain-Specific-Words/"/>
    <id>http://qpchen.tk/2019/02/25/2019-02-25-Domain-Specific-Words/</id>
    <published>2019-02-25T10:59:34.000Z</published>
    <updated>2019-03-07T04:00:54.000Z</updated>
    
    <content type="html"><![CDATA[<p>This is a record of normal words in computer science domain.</p><h2 id="Domain-Specific-Words"><a href="#Domain-Specific-Words" class="headerlink" title="Domain Specific Words"></a>Domain Specific Words</h2><h3 id="Vanilla-Code"><a href="#Vanilla-Code" class="headerlink" title="Vanilla Code"></a>Vanilla Code</h3><p>Vanilla often refers to pure or plain. So in terms of programming languages, it means either without the use of 3rd party libraries or without the use of frameworks.</p><p>在计算机编程的范畴中，通常表示不使用第三方库或任何相关的框架平台等。</p><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This is a record of normal words in computer science domain.&lt;/p&gt;
&lt;h2 id=&quot;Domain-Specific-Words&quot;&gt;&lt;a href=&quot;#Domain-Specific-Words&quot; class=&quot;headerlink&quot; title=&quot;Domain Specific Words&quot;&gt;&lt;/a&gt;Domain Specific Words&lt;/h2&gt;&lt;h3 id=&quot;Vanilla-Code&quot;&gt;&lt;a href=&quot;#Vanilla-Code&quot; class=&quot;headerlink&quot; title=&quot;Vanilla Code&quot;&gt;&lt;/a&gt;Vanilla Code&lt;/h3&gt;&lt;p&gt;Vanilla often refers to pure or plain. So in terms of programming languages, it means either without the use of 3rd party libraries or without the use of frameworks.&lt;/p&gt;
&lt;p&gt;在计算机编程的范畴中，通常表示不使用第三方库或任何相关的框架平台等。&lt;/p&gt;
    
    </summary>
    
      <category term="General Concept" scheme="http://qpchen.tk/categories/General-Concept/"/>
    
    
      <category term="Computer Science" scheme="http://qpchen.tk/tags/Computer-Science/"/>
    
      <category term="Record" scheme="http://qpchen.tk/tags/Record/"/>
    
  </entry>
  
</feed>
